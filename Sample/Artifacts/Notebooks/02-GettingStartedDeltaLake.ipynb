{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hitchhiker's Guide to Delta Lake (Python)\n",
        "\n",
        "This tutorial has been adapted for more clarity from its original counterpart [here](https://docs.delta.io/latest/quick-start.html). This notebook helps you quickly explore the main features of [Delta Lake](https://github.com/delta-io/delta). It provides code snippets that show how to read from and write to Delta Lake tables from interactive, batch, and streaming queries.\n",
        "\n",
        "Here's what we will cover:\n",
        "* Create a table\n",
        "* Understanding meta-data\n",
        "* Read data\n",
        "* Update table data\n",
        "* Overwrite table data\n",
        "* Conditional update without overwrite\n",
        "* Read older versions of data using Time Travel\n",
        "* Write a stream of data to a table\n",
        "* Read a stream of changes from a table"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration\n",
        "Make sure you modify this as appropriate."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "session_id = random.randint(0,1000000)\n",
        "delta_table_path = \"/delta/delta-table-{0}\".format(session_id)\n",
        "\n",
        "delta_table_path"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "session_starting",
              "livy_statement_state": null,
              "queued_time": "2022-03-23T23:16:15.54984Z",
              "session_start_time": "2022-03-23T23:16:15.5847953Z",
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , SessionStarting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a table\n",
        "To create a Delta Lake table, write a DataFrame out in the **delta** format. You can use existing Spark SQL code and change the format from parquet, csv, json, and so on, to delta.\n",
        "\n",
        "These operations create a new Delta Lake table using the schema that was inferred from your DataFrame. For the full set of options available when you create a new Delta Lake table, see Create a table and Write to a table (subsequent cells in this notebook)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.range(0,5)\n",
        "data.show()\n",
        "data.write.format(\"delta\").save(delta_table_path)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.1996891Z",
              "execution_start_time": "2021-02-23T05:31:25.4988783Z",
              "execution_finish_time": "2021-02-23T05:31:52.411739Z"
            },
            "text/plain": "StatementMeta(small, 8, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "+---+\n| id|\n+---+\n|  0|\n|  1|\n|  2|\n|  3|\n|  4|\n+---+"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Meta-data\n",
        "\n",
        "In Delta Lake, meta-data is no different from data i.e., it is stored next to the data. Therefore, an interesting side-effect here is that you can peek into meta-data using regular Spark APIs. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "[log_line.value for log_line in spark.read.text(delta_table_path + \"/_delta_log/\").collect()]"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.2264512Z",
              "execution_start_time": "2021-02-23T05:31:52.4888873Z",
              "execution_finish_time": "2021-02-23T05:31:54.5313944Z"
            },
            "text/plain": "StatementMeta(small, 8, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "['{\"commitInfo\":{\"timestamp\":1614058299692,\"operation\":\"WRITE\",\"operationParameters\":{\"mode\":\"ErrorIfExists\",\"partitionBy\":\"[]\"},\"isBlindAppend\":true,\"operationMetrics\":{\"numFiles\":\"6\",\"numOutputBytes\":\"2407\",\"numOutputRows\":\"5\"}}}', '{\"protocol\":{\"minReaderVersion\":1,\"minWriterVersion\":2}}', '{\"metaData\":{\"id\":\"d12e1f0b-a3f5-4ebd-840b-dc7b4c4b46a1\",\"format\":{\"provider\":\"parquet\",\"options\":{}},\"schemaString\":\"{\\\\\"type\\\\\":\\\\\"struct\\\\\",\\\\\"fields\\\\\":[{\\\\\"name\\\\\":\\\\\"id\\\\\",\\\\\"type\\\\\":\\\\\"long\\\\\",\\\\\"nullable\\\\\":true,\\\\\"metadata\\\\\":{}}]}\",\"partitionColumns\":[],\"configuration\":{},\"createdTime\":1614058292359}}', '{\"add\":{\"path\":\"part-00000-34c67853-75ca-44a6-afdc-86a242188b51-c000.snappy.parquet\",\"partitionValues\":{},\"size\":262,\"modificationTime\":1614058299000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00001-a850ac70-058b-4b39-9ca2-ba25586e8b5c-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058297000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00003-7cc9fc73-04cb-477c-8ea3-4bceb0b5833e-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058297000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00004-7211fe7e-145f-4ee6-8fe0-387af071e4f1-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058299000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00006-9c0d558c-a845-4ef5-b312-edc34624ea3d-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058299000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00007-9a080053-ebbe-48d7-bdd5-75feb84b797a-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058297000,\"dataChange\":true}}']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data\n",
        "\n",
        "You read data in your Delta Lake table by specifying the path to the files."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"delta\").load(delta_table_path)\n",
        "df.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.2526539Z",
              "execution_start_time": "2021-02-23T05:31:54.6005152Z",
              "execution_finish_time": "2021-02-23T05:31:58.6833846Z"
            },
            "text/plain": "StatementMeta(small, 8, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "+---+\n| id|\n+---+\n|  4|\n|  0|\n|  1|\n|  3|\n|  2|\n+---+"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update table data\n",
        "\n",
        "Delta Lake supports several operations to modify tables using standard DataFrame APIs. This example runs a batch job to overwrite the data in the table.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.range(5,10)\n",
        "data.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)\n",
        "df.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.2805413Z",
              "execution_start_time": "2021-02-23T05:31:58.7492438Z",
              "execution_finish_time": "2021-02-23T05:32:06.887283Z"
            },
            "text/plain": "StatementMeta(small, 8, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "+---+\n| id|\n+---+\n|  6|\n|  5|\n|  9|\n|  8|\n|  7|\n+---+"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you now inspect the meta-data, what you will notice is that the original data is over-written. Well, not in a true sense but appropriate entries are added to Delta's transaction log so it can provide an \"illusion\" that the original data was deleted. We can verify this by re-inspecting the meta-data. You will see several entries indicating reference removal to the original data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "[log_line.value for log_line in spark.read.text(delta_table_path + \"/_delta_log/\").collect()]"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.3124177Z",
              "execution_start_time": "2021-02-23T05:32:06.9566743Z",
              "execution_finish_time": "2021-02-23T05:32:09.0074073Z"
            },
            "text/plain": "StatementMeta(small, 8, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "['{\"commitInfo\":{\"timestamp\":1614058320094,\"operation\":\"WRITE\",\"operationParameters\":{\"mode\":\"Overwrite\",\"partitionBy\":\"[]\"},\"readVersion\":0,\"isBlindAppend\":false,\"operationMetrics\":{\"numFiles\":\"6\",\"numOutputBytes\":\"2407\",\"numOutputRows\":\"5\"}}}', '{\"add\":{\"path\":\"part-00000-bb518901-f07c-434c-9140-83798465da11-c000.snappy.parquet\",\"partitionValues\":{},\"size\":262,\"modificationTime\":1614058319000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00001-8c1ef250-dbab-4bbb-857a-26aa9f05c421-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058319000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00003-fa61da74-e9c6-4028-90ff-f75a1a8a553d-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058319000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00004-044398cd-b135-4581-a490-22beba084210-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058319000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00006-1557c4bb-8e50-489f-8801-3cd9d9d5dc1a-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058319000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00007-8bbd5b7f-da19-4609-a1ab-5b15d89b82cf-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058319000,\"dataChange\":true}}', '{\"remove\":{\"path\":\"part-00007-9a080053-ebbe-48d7-bdd5-75feb84b797a-c000.snappy.parquet\",\"deletionTimestamp\":1614058320094,\"dataChange\":true}}', '{\"remove\":{\"path\":\"part-00001-a850ac70-058b-4b39-9ca2-ba25586e8b5c-c000.snappy.parquet\",\"deletionTimestamp\":1614058320094,\"dataChange\":true}}', '{\"remove\":{\"path\":\"part-00000-34c67853-75ca-44a6-afdc-86a242188b51-c000.snappy.parquet\",\"deletionTimestamp\":1614058320094,\"dataChange\":true}}', '{\"remove\":{\"path\":\"part-00003-7cc9fc73-04cb-477c-8ea3-4bceb0b5833e-c000.snappy.parquet\",\"deletionTimestamp\":1614058320094,\"dataChange\":true}}', '{\"remove\":{\"path\":\"part-00006-9c0d558c-a845-4ef5-b312-edc34624ea3d-c000.snappy.parquet\",\"deletionTimestamp\":1614058320094,\"dataChange\":true}}', '{\"remove\":{\"path\":\"part-00004-7211fe7e-145f-4ee6-8fe0-387af071e4f1-c000.snappy.parquet\",\"deletionTimestamp\":1614058320094,\"dataChange\":true}}', '{\"commitInfo\":{\"timestamp\":1614058299692,\"operation\":\"WRITE\",\"operationParameters\":{\"mode\":\"ErrorIfExists\",\"partitionBy\":\"[]\"},\"isBlindAppend\":true,\"operationMetrics\":{\"numFiles\":\"6\",\"numOutputBytes\":\"2407\",\"numOutputRows\":\"5\"}}}', '{\"protocol\":{\"minReaderVersion\":1,\"minWriterVersion\":2}}', '{\"metaData\":{\"id\":\"d12e1f0b-a3f5-4ebd-840b-dc7b4c4b46a1\",\"format\":{\"provider\":\"parquet\",\"options\":{}},\"schemaString\":\"{\\\\\"type\\\\\":\\\\\"struct\\\\\",\\\\\"fields\\\\\":[{\\\\\"name\\\\\":\\\\\"id\\\\\",\\\\\"type\\\\\":\\\\\"long\\\\\",\\\\\"nullable\\\\\":true,\\\\\"metadata\\\\\":{}}]}\",\"partitionColumns\":[],\"configuration\":{},\"createdTime\":1614058292359}}', '{\"add\":{\"path\":\"part-00000-34c67853-75ca-44a6-afdc-86a242188b51-c000.snappy.parquet\",\"partitionValues\":{},\"size\":262,\"modificationTime\":1614058299000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00001-a850ac70-058b-4b39-9ca2-ba25586e8b5c-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058297000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00003-7cc9fc73-04cb-477c-8ea3-4bceb0b5833e-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058297000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00004-7211fe7e-145f-4ee6-8fe0-387af071e4f1-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058299000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00006-9c0d558c-a845-4ef5-b312-edc34624ea3d-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058299000,\"dataChange\":true}}', '{\"add\":{\"path\":\"part-00007-9a080053-ebbe-48d7-bdd5-75feb84b797a-c000.snappy.parquet\",\"partitionValues\":{},\"size\":429,\"modificationTime\":1614058297000,\"dataChange\":true}}']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save as catalog tables\n",
        "\n",
        "Delta Lake can write to managed or external catalog tables."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Write data to a new managed catalog table.\n",
        "data.write.format(\"delta\").saveAsTable(\"ManagedDeltaTable\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.341202Z",
              "execution_start_time": "2021-02-23T05:32:09.0763818Z",
              "execution_finish_time": "2021-02-23T05:32:15.1895071Z"
            },
            "text/plain": "StatementMeta(small, 8, 9, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an external catalog table that points to the existing Delta Lake data in storage.\n",
        "spark.sql(\"CREATE TABLE ExternalDeltaTable USING DELTA LOCATION '{0}'\".format(delta_table_path))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.3699896Z",
              "execution_start_time": "2021-02-23T05:32:15.2552238Z",
              "execution_finish_time": "2021-02-23T05:32:17.3020792Z"
            },
            "text/plain": "StatementMeta(small, 8, 10, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "DataFrame[]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# List the 2 new tables.\n",
        "spark.sql(\"SHOW TABLES\").show()\n",
        "\n",
        "# Explore their properties.\n",
        "spark.sql(\"DESCRIBE EXTENDED ManagedDeltaTable\").show(truncate=False)\n",
        "spark.sql(\"DESCRIBE EXTENDED ExternalDeltaTable\").show(truncate=False)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 11,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.3948988Z",
              "execution_start_time": "2021-02-23T05:32:17.3711514Z",
              "execution_finish_time": "2021-02-23T05:32:19.4014176Z"
            },
            "text/plain": "StatementMeta(small, 8, 11, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "+--------+--------------------+-----------+\n|database|           tableName|isTemporary|\n+--------+--------------------+-----------+\n| default|  externaldeltatable|      false|\n| default|   manageddeltatable|      false|\n| default|            nyc_taxi|      false|\n| default|nyc_taxi_synapse_...|      false|\n| default|       yourtablename|      false|\n+--------+--------------------+-----------+\n\n+----------------------------+------------------------------------------------------------------------------------------------------------+-------+\n|col_name                    |data_type                                                                                                   |comment|\n+----------------------------+------------------------------------------------------------------------------------------------------------+-------+\n|id                          |bigint                                                                                                      |null   |\n|                            |                                                                                                            |       |\n|# Detailed Table Information|                                                                                                            |       |\n|Database                    |default                                                                                                     |       |\n|Table                       |manageddeltatable                                                                                           |       |\n|Owner                       |trusted-service-user                                                                                        |       |\n|Created Time                |Tue Feb 23 05:32:13 UTC 2021                                                                                |       |\n|Last Access                 |Thu Jan 01 00:00:00 UTC 1970                                                                                |       |\n|Created By                  |Spark 2.4.4.2.6.99.201-28062795                                                                             |       |\n|Type                        |MANAGED                                                                                                     |       |\n|Provider                    |delta                                                                                                       |       |\n|Table Properties            |[transient_lastDdlTime=1614058333]                                                                          |       |\n|Statistics                  |2407 bytes                                                                                                  |       |\n|Location                    |abfss://zhaotest@bdbjtestgen2.dfs.core.windows.net/synapse/workspaces/bdbj0223ws/warehouse/manageddeltatable|       |\n|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                                                          |       |\n|InputFormat                 |org.apache.hadoop.mapred.SequenceFileInputFormat                                                            |       |\n|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat                                                   |       |\n|Storage Properties          |[serialization.format=1]                                                                                    |       |\n+----------------------------+------------------------------------------------------------------------------------------------------------+-------+\n\n+----------------------------+---------------------------------------------------------------------------+-------+\n|col_name                    |data_type                                                                  |comment|\n+----------------------------+---------------------------------------------------------------------------+-------+\n|id                          |bigint                                                                     |null   |\n|                            |                                                                           |       |\n|# Detailed Table Information|                                                                           |       |\n|Database                    |default                                                                    |       |\n|Table                       |externaldeltatable                                                         |       |\n|Owner                       |trusted-service-user                                                       |       |\n|Created Time                |Tue Feb 23 05:32:15 UTC 2021                                               |       |\n|Last Access                 |Thu Jan 01 00:00:00 UTC 1970                                               |       |\n|Created By                  |Spark 2.4.4.2.6.99.201-28062795                                            |       |\n|Type                        |EXTERNAL                                                                   |       |\n|Provider                    |DELTA                                                                      |       |\n|Table Properties            |[transient_lastDdlTime=1614058335]                                         |       |\n|Location                    |abfss://zhaotest@bdbjtestgen2.dfs.core.windows.net/delta/delta-table-599938|       |\n|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                         |       |\n|InputFormat                 |org.apache.hadoop.mapred.SequenceFileInputFormat                           |       |\n|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat                  |       |\n|Storage Properties          |[serialization.format=1]                                                   |       |\n+----------------------------+---------------------------------------------------------------------------+-------+"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conditional update without overwrite\n",
        "\n",
        "Delta Lake provides programmatic APIs to conditional update, delete, and merge (upsert) data into tables. For more information on these operations, see [Table Deletes, Updates, and Merges](https://docs.delta.io/latest/delta-update.html)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from delta.tables import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "delta_table = DeltaTable.forPath(spark, delta_table_path)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 12,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.420674Z",
              "execution_start_time": "2021-02-23T05:32:19.4755548Z",
              "execution_finish_time": "2021-02-23T05:32:21.5122504Z"
            },
            "text/plain": "StatementMeta(small, 8, 12, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Update every even value by adding 100 to it\n",
        "delta_table.update(\n",
        "  condition = expr(\"id % 2 == 0\"),\n",
        "  set = { \"id\": expr(\"id + 100\") })\n",
        "delta_table.toDF().show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 13,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.4479842Z",
              "execution_start_time": "2021-02-23T05:32:21.5816261Z",
              "execution_finish_time": "2021-02-23T05:32:27.6970519Z"
            },
            "text/plain": "StatementMeta(small, 8, 13, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "+---+\n| id|\n+---+\n|  5|\n|  9|\n|106|\n|108|\n|  7|\n+---+"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete every even value\n",
        "delta_table.delete(\"id % 2 == 0\")\n",
        "delta_table.toDF().show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 14,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.4750426Z",
              "execution_start_time": "2021-02-23T05:32:27.7621047Z",
              "execution_finish_time": "2021-02-23T05:32:33.8862947Z"
            },
            "text/plain": "StatementMeta(small, 8, 14, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "+---+\n| id|\n+---+\n|  5|\n|  9|\n|  7|\n+---+"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Upsert (merge) new data\n",
        "new_data = spark.range(0,20).alias(\"newData\")\n",
        "\n",
        "delta_table.alias(\"oldData\")\\\n",
        "    .merge(new_data.alias(\"newData\"), \"oldData.id = newData.id\")\\\n",
        "    .whenMatchedUpdate(set = { \"id\": lit(\"-1\")})\\\n",
        "    .whenNotMatchedInsert(values = { \"id\": col(\"newData.id\") })\\\n",
        "    .execute()\n",
        "\n",
        "delta_table.toDF().show(100)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 15,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.5015095Z",
              "execution_start_time": "2021-02-23T05:32:33.9539979Z",
              "execution_finish_time": "2021-02-23T05:32:46.2287469Z"
            },
            "text/plain": "StatementMeta(small, 8, 15, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "+---+\n| id|\n+---+\n| 12|\n| -1|\n| 16|\n|  2|\n|  0|\n| 11|\n| 18|\n|  6|\n| 15|\n| 19|\n| 14|\n| -1|\n|  8|\n| 10|\n|  4|\n| 13|\n| -1|\n| 17|\n|  1|\n|  3|\n+---+"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## History\n",
        "Delta's most powerful feature is the ability to allow looking into history i.e., the changes that were made to the underlying Delta Table. The cell below shows how simple it is to inspect the history."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "delta_table.history().show(20, 1000, False)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 16,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.5304026Z",
              "execution_start_time": "2021-02-23T05:32:46.2988905Z",
              "execution_finish_time": "2021-02-23T05:32:48.3284699Z"
            },
            "text/plain": "StatementMeta(small, 8, 16, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "+-------+-------------------+------+--------+---------+-------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|version|          timestamp|userId|userName|operation|                                                operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|                                                                                                                                                                                              operationMetrics|\n+-------+-------------------+------+--------+---------+-------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|      4|2021-02-23 05:32:40|  null|    null|    MERGE|                       [predicate -> (oldData.`id` = newData.`id`)]|null|    null|     null|          3|          null|        false|[numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 21, numTargetRowsInserted -> 17, numTargetRowsUpdated -> 3, numOutputRows -> 20, numSourceRows -> 20, numTargetFilesRemoved -> 3]|\n|      3|2021-02-23 05:32:29|  null|    null|   DELETE|[predicate -> [\"((`id` % CAST(2 AS BIGINT)) = CAST(0 AS BIGINT))\"]]|null|    null|     null|          2|          null|        false|                                                                                                                           [numRemovedFiles -> 2, numDeletedRows -> 2, numAddedFiles -> 1, numCopiedRows -> 0]|\n|      2|2021-02-23 05:32:24|  null|    null|   UPDATE| [predicate -> ((id#505L % cast(2 as bigint)) = cast(0 as bigint))]|null|    null|     null|          1|          null|        false|                                                                                                                           [numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 2, numCopiedRows -> 0]|\n|      1|2021-02-23 05:32:00|  null|    null|    WRITE|                             [mode -> Overwrite, partitionBy -> []]|null|    null|     null|          0|          null|        false|                                                                                                                                                   [numFiles -> 6, numOutputBytes -> 2407, numOutputRows -> 5]|\n|      0|2021-02-23 05:31:39|  null|    null|    WRITE|                         [mode -> ErrorIfExists, partitionBy -> []]|null|    null|     null|       null|          null|         true|                                                                                                                                                   [numFiles -> 6, numOutputBytes -> 2407, numOutputRows -> 5]|\n+-------+-------------------+------+--------+---------+-------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read older versions of data using Time Travel\n",
        "\n",
        "You can query previous snapshots of your Delta Lake table by using a feature called Time Travel. If you want to access the data that you overwrote, you can query a snapshot of the table before you overwrote the first set of data using the versionAsOf option.\n",
        "\n",
        "Once you run the cell below, you should see the first set of data, from before you overwrote it. Time Travel is an extremely powerful feature that takes advantage of the power of the Delta Lake transaction log to access data that is no longer in the table. Removing the version 0 option (or specifying version 1) would let you see the newer data again. For more information, see [Query an older snapshot of a table (time travel)](https://docs.delta.io/latest/delta-batch.html#deltatimetravel)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_table_path)\n",
        "df.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 17,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.5616657Z",
              "execution_start_time": "2021-02-23T05:32:48.3986144Z",
              "execution_finish_time": "2021-02-23T05:32:54.5085826Z"
            },
            "text/plain": "StatementMeta(small, 8, 17, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "+---+\n| id|\n+---+\n|  4|\n|  0|\n|  1|\n|  3|\n|  2|\n+---+"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write a stream of data to a table\n",
        "\n",
        "You can also write to a Delta Lake table using Spark's Structured Streaming. The Delta Lake transaction log guarantees exactly-once processing, even when there are other streams or batch queries running concurrently against the table. By default, streams run in append mode, which adds new records to the table.\n",
        "\n",
        "For more information about Delta Lake integration with Structured Streaming, see [Table Streaming Reads and Writes](https://docs.delta.io/latest/delta-streaming.html).\n",
        "\n",
        "In the cells below, here's what we are doing:\n",
        "\n",
        "1. *Cell 28* Setup a simple Spark Structured Streaming job to generate a sequence and make the job write into our Delta Table\n",
        "2. *Cell 30* Show the newly appended data\n",
        "3. *Cell 31* Inspect history\n",
        "4. *Cell 32* Stop the structured streaming job\n",
        "5. *Cell 33* Inspect history <-- You'll notice appends have stopped"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "streaming_df = spark.readStream.format(\"rate\").load()\n",
        "stream = streaming_df\\\n",
        "    .selectExpr(\"value as id\")\\\n",
        "    .writeStream\\\n",
        "    .format(\"delta\")\\\n",
        "    .option(\"checkpointLocation\", \"/tmp/checkpoint-{0}\".format(session_id))\\\n",
        "    .start(delta_table_path)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 18,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.6136965Z",
              "execution_start_time": "2021-02-23T05:32:54.5955644Z",
              "execution_finish_time": "2021-02-23T05:32:56.6322581Z"
            },
            "text/plain": "StatementMeta(small, 8, 18, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read a stream of changes from a table\n",
        "\n",
        "While the stream is writing to the Delta Lake table, you can also read from that table as streaming source. For example, you can start another streaming query that prints all the changes made to the Delta Lake table."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "delta_table.toDF().sort(col(\"id\").desc()).show(100)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 19,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.6459503Z",
              "execution_start_time": "2021-02-23T05:32:56.6980466Z",
              "execution_finish_time": "2021-02-23T05:33:00.7933178Z"
            },
            "text/plain": "StatementMeta(small, 8, 19, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "+---+\n| id|\n+---+\n| 19|\n| 18|\n| 17|\n| 16|\n| 15|\n| 14|\n| 13|\n| 12|\n| 11|\n| 10|\n|  8|\n|  6|\n|  4|\n|  3|\n|  2|\n|  1|\n|  0|\n| -1|\n| -1|\n| -1|\n+---+"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "delta_table.history().drop(\"userId\", \"userName\", \"job\", \"notebook\", \"clusterId\", \"isolationLevel\", \"isBlindAppend\").show(20, 1000, False)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 20,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.671101Z",
              "execution_start_time": "2021-02-23T05:33:00.8607701Z",
              "execution_finish_time": "2021-02-23T05:33:02.8979611Z"
            },
            "text/plain": "StatementMeta(small, 8, 20, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "+-------+-------------------+----------------+-------------------------------------------------------------------------------------+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|version|          timestamp|       operation|                                                                  operationParameters|readVersion|                                                                                                                                                                                              operationMetrics|\n+-------+-------------------+----------------+-------------------------------------------------------------------------------------+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|      6|2021-02-23 05:32:59|STREAMING UPDATE|[outputMode -> Append, queryId -> 348def45-706c-4555-ab12-178864ea7338, epochId -> 1]|          5|                                                                                                                        [numRemovedFiles -> 0, numOutputRows -> 3, numOutputBytes -> 1287, numAddedFiles -> 3]|\n|      5|2021-02-23 05:32:56|STREAMING UPDATE|[outputMode -> Append, queryId -> 348def45-706c-4555-ab12-178864ea7338, epochId -> 0]|          4|                                                                                                                         [numRemovedFiles -> 0, numOutputRows -> 0, numOutputBytes -> 262, numAddedFiles -> 1]|\n|      4|2021-02-23 05:32:40|           MERGE|                                         [predicate -> (oldData.`id` = newData.`id`)]|          3|[numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 21, numTargetRowsInserted -> 17, numTargetRowsUpdated -> 3, numOutputRows -> 20, numSourceRows -> 20, numTargetFilesRemoved -> 3]|\n|      3|2021-02-23 05:32:29|          DELETE|                  [predicate -> [\"((`id` % CAST(2 AS BIGINT)) = CAST(0 AS BIGINT))\"]]|          2|                                                                                                                           [numRemovedFiles -> 2, numDeletedRows -> 2, numAddedFiles -> 1, numCopiedRows -> 0]|\n|      2|2021-02-23 05:32:24|          UPDATE|                   [predicate -> ((id#505L % cast(2 as bigint)) = cast(0 as bigint))]|          1|                                                                                                                           [numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 2, numCopiedRows -> 0]|\n|      1|2021-02-23 05:32:00|           WRITE|                                               [mode -> Overwrite, partitionBy -> []]|          0|                                                                                                                                                   [numFiles -> 6, numOutputBytes -> 2407, numOutputRows -> 5]|\n|      0|2021-02-23 05:31:39|           WRITE|                                           [mode -> ErrorIfExists, partitionBy -> []]|       null|                                                                                                                                                   [numFiles -> 6, numOutputBytes -> 2407, numOutputRows -> 5]|\n+-------+-------------------+----------------+-------------------------------------------------------------------------------------+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "stream.stop()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 21,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.7008471Z",
              "execution_start_time": "2021-02-23T05:33:02.9652369Z",
              "execution_finish_time": "2021-02-23T05:33:05.0045411Z"
            },
            "text/plain": "StatementMeta(small, 8, 21, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "delta_table.history().drop(\"userId\", \"userName\", \"job\", \"notebook\", \"clusterId\", \"isolationLevel\", \"isBlindAppend\").show(100, 1000, False)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 22,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.7277187Z",
              "execution_start_time": "2021-02-23T05:33:05.0738409Z",
              "execution_finish_time": "2021-02-23T05:33:09.144476Z"
            },
            "text/plain": "StatementMeta(small, 8, 22, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "+-------+-------------------+----------------+-------------------------------------------------------------------------------------+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|version|          timestamp|       operation|                                                                  operationParameters|readVersion|                                                                                                                                                                                              operationMetrics|\n+-------+-------------------+----------------+-------------------------------------------------------------------------------------+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|      7|2021-02-23 05:33:02|STREAMING UPDATE|[outputMode -> Append, queryId -> 348def45-706c-4555-ab12-178864ea7338, epochId -> 2]|          6|                                                                                                                        [numRemovedFiles -> 0, numOutputRows -> 3, numOutputBytes -> 1287, numAddedFiles -> 3]|\n|      6|2021-02-23 05:32:59|STREAMING UPDATE|[outputMode -> Append, queryId -> 348def45-706c-4555-ab12-178864ea7338, epochId -> 1]|          5|                                                                                                                        [numRemovedFiles -> 0, numOutputRows -> 3, numOutputBytes -> 1287, numAddedFiles -> 3]|\n|      5|2021-02-23 05:32:56|STREAMING UPDATE|[outputMode -> Append, queryId -> 348def45-706c-4555-ab12-178864ea7338, epochId -> 0]|          4|                                                                                                                         [numRemovedFiles -> 0, numOutputRows -> 0, numOutputBytes -> 262, numAddedFiles -> 1]|\n|      4|2021-02-23 05:32:40|           MERGE|                                         [predicate -> (oldData.`id` = newData.`id`)]|          3|[numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 21, numTargetRowsInserted -> 17, numTargetRowsUpdated -> 3, numOutputRows -> 20, numSourceRows -> 20, numTargetFilesRemoved -> 3]|\n|      3|2021-02-23 05:32:29|          DELETE|                  [predicate -> [\"((`id` % CAST(2 AS BIGINT)) = CAST(0 AS BIGINT))\"]]|          2|                                                                                                                           [numRemovedFiles -> 2, numDeletedRows -> 2, numAddedFiles -> 1, numCopiedRows -> 0]|\n|      2|2021-02-23 05:32:24|          UPDATE|                   [predicate -> ((id#505L % cast(2 as bigint)) = cast(0 as bigint))]|          1|                                                                                                                           [numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 2, numCopiedRows -> 0]|\n|      1|2021-02-23 05:32:00|           WRITE|                                               [mode -> Overwrite, partitionBy -> []]|          0|                                                                                                                                                   [numFiles -> 6, numOutputBytes -> 2407, numOutputRows -> 5]|\n|      0|2021-02-23 05:31:39|           WRITE|                                           [mode -> ErrorIfExists, partitionBy -> []]|       null|                                                                                                                                                   [numFiles -> 6, numOutputBytes -> 2407, numOutputRows -> 5]|\n+-------+-------------------+----------------+-------------------------------------------------------------------------------------+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compaction\n",
        "\n",
        "If a Delta Table is growing too large, you can compact it by repartitioning into a smaller number of files.\n",
        "\n",
        "The option `dataChange = false` is an optimization that tells Delta Lake to do the repartition without marking the underlying data as \"modified\". This ensures that any other concurrent operations (such as streaming reads/writes) aren't negatively impacted.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "partition_count = 2\n",
        "\n",
        "spark.read\\\n",
        "    .format(\"delta\")\\\n",
        "    .load(delta_table_path)\\\n",
        "    .repartition(partition_count)\\\n",
        "    .write.option(\"dataChange\", \"false\")\\\n",
        "    .format(\"delta\")\\\n",
        "    .mode(\"overwrite\")\\\n",
        "    .save(delta_table_path)    "
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 23,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.7589925Z",
              "execution_start_time": "2021-02-23T05:33:09.2084583Z",
              "execution_finish_time": "2021-02-23T05:33:13.282982Z"
            },
            "text/plain": "StatementMeta(small, 8, 23, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Parquet to Delta\n",
        "You can do an in-place conversion from the Parquet format to Delta."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "parquet_path = \"/parquet/parquet-table-{0}\".format(session_id)\n",
        "\n",
        "data = spark.range(0,5)\n",
        "data.write.parquet(parquet_path)\n",
        "\n",
        "# Confirm that the data isn't in the Delta format\n",
        "DeltaTable.isDeltaTable(spark, parquet_path)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 24,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.7858231Z",
              "execution_start_time": "2021-02-23T05:33:13.3440872Z",
              "execution_finish_time": "2021-02-23T05:33:15.3850601Z"
            },
            "text/plain": "StatementMeta(small, 8, 24, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "False"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "DeltaTable.convertToDelta(spark, \"parquet.`{0}`\".format(parquet_path))\n",
        "\n",
        "# Confirm that the converted data is now in the Delta format\n",
        "DeltaTable.isDeltaTable(spark, parquet_path)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 25,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.8122425Z",
              "execution_start_time": "2021-02-23T05:33:15.4466781Z",
              "execution_finish_time": "2021-02-23T05:33:23.6025483Z"
            },
            "text/plain": "StatementMeta(small, 8, 25, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SQL Support\n",
        "Delta supports table utility commands through SQL.  You can use SQL to:\n",
        "* Get a DeltaTable's history\n",
        "* Vacuum a DeltaTable\n",
        "* Convert a Parquet file to Delta\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"DESCRIBE HISTORY delta.`{0}`\".format(delta_table_path)).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 26,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.8361807Z",
              "execution_start_time": "2021-02-23T05:33:23.684799Z",
              "execution_finish_time": "2021-02-23T05:33:25.7228079Z"
            },
            "text/plain": "StatementMeta(small, 8, 26, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "+-------+-------------------+------+--------+----------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+\n|version|          timestamp|userId|userName|       operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|\n+-------+-------------------+------+--------+----------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+\n|      8|2021-02-23 05:33:11|  null|    null|           WRITE|[mode -> Overwrit...|null|    null|     null|          7|          null|        false|[numFiles -> 2, n...|\n|      7|2021-02-23 05:33:02|  null|    null|STREAMING UPDATE|[outputMode -> Ap...|null|    null|     null|          6|          null|         true|[numRemovedFiles ...|\n|      6|2021-02-23 05:32:59|  null|    null|STREAMING UPDATE|[outputMode -> Ap...|null|    null|     null|          5|          null|         true|[numRemovedFiles ...|\n|      5|2021-02-23 05:32:56|  null|    null|STREAMING UPDATE|[outputMode -> Ap...|null|    null|     null|          4|          null|         true|[numRemovedFiles ...|\n|      4|2021-02-23 05:32:40|  null|    null|           MERGE|[predicate -> (ol...|null|    null|     null|          3|          null|        false|[numTargetRowsCop...|\n|      3|2021-02-23 05:32:29|  null|    null|          DELETE|[predicate -> [\"(...|null|    null|     null|          2|          null|        false|[numRemovedFiles ...|\n|      2|2021-02-23 05:32:24|  null|    null|          UPDATE|[predicate -> ((i...|null|    null|     null|          1|          null|        false|[numRemovedFiles ...|\n|      1|2021-02-23 05:32:00|  null|    null|           WRITE|[mode -> Overwrit...|null|    null|     null|          0|          null|        false|[numFiles -> 6, n...|\n|      0|2021-02-23 05:31:39|  null|    null|           WRITE|[mode -> ErrorIfE...|null|    null|     null|       null|          null|         true|[numFiles -> 6, n...|\n+-------+-------------------+------+--------+----------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"VACUUM delta.`{0}`\".format(delta_table_path)).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 27,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.862963Z",
              "execution_start_time": "2021-02-23T05:33:25.7884175Z",
              "execution_finish_time": "2021-02-23T05:34:18.6026171Z"
            },
            "text/plain": "StatementMeta(small, 8, 27, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "+--------------------+\n|                path|\n+--------------------+\n|abfss://zhaotest@...|\n+--------------------+"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "parquet_id = random.randint(0,1000)\n",
        "parquet_path = \"/parquet/parquet-table-{0}-{1}\".format(session_id, parquet_path)\n",
        "\n",
        "data = spark.range(0,5)\n",
        "data.write.parquet(parquet_path)\n",
        "\n",
        "# Confirm that the data isn't in the Delta format\n",
        "DeltaTable.isDeltaTable(spark, parquet_path)\n",
        "\n",
        "# Use SQL to convert the parquet table to Delta\n",
        "spark.sql(\"CONVERT TO DELTA parquet.`{0}`\".format(parquet_path))\n",
        "\n",
        "DeltaTable.isDeltaTable(spark, parquet_path)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "small",
              "session_id": 8,
              "statement_id": 28,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-02-23T05:30:38.8863961Z",
              "execution_start_time": "2021-02-23T05:34:18.6732815Z",
              "execution_finish_time": "2021-02-23T05:34:24.8572968Z"
            },
            "text/plain": "StatementMeta(small, 8, 28, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}